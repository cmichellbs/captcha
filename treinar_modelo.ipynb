{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03abf245-4714-4c11-b843-7a30434691f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from helpers import resize_to_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c2ea2fc-09f4-4392-91db-f1583c05b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = []\n",
    "rotulos = []\n",
    "pasta_base_imagens = 'base_letras'\n",
    "imagens = paths.list_images(pasta_base_imagens)\n",
    "for arquivo in imagens:\n",
    "    rotulo = arquivo.split(os.path.sep)[-2]\n",
    "    imagem = cv2.imread(arquivo)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    #PADRONIZAR TAMANHO IMAGEM 90X150\n",
    "    imagem = resize_to_fit(imagem,30,30)\n",
    "    \n",
    "    #ADICIONAR DIMENSÃO 2\n",
    "    imagem = np.expand_dims(imagem,axis=2)\n",
    "    \n",
    "    #ADICIONAR A DATA E LABEL\n",
    "    rotulos.append(rotulo)\n",
    "    dados.append(imagem)\n",
    "dados = np.array(dados,dtype=\"float\")/255\n",
    "rotulos = np.array(rotulos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e383c04-6e28-47a5-8307-ad5626584234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados de treino e dados de teste\n",
    "\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(dados, rotulos, test_size=0.25)\n",
    "#converter em on-hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ed5b33b-391a-4f2d-950e-b081f43e7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer().fit(Y_train)\n",
    "\n",
    "Y_train = lb.transform(Y_train)\n",
    "Y_test = lb.transform(Y_test)\n",
    "\n",
    "# salvar o LabelBinarizer com pickle\n",
    "\n",
    "with open('rotulos_modelo.dat','wb') as arquivo_pickle:\n",
    "    pickle.dump(lb, arquivo_pickle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88e43e5c-5c53-42bf-896e-49dee92524aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar modelo\n",
    "\n",
    "modelo = Sequential()\n",
    "\n",
    "# criar as camadas da rede neural\n",
    "modelo.add(Conv2D(60,(5,5), padding=\"same\", input_shape=(30,30,1), activation=\"relu\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# criar a 2ª camada\n",
    "modelo.add(Conv2D(150,(5, 5), padding=\"same\", activation=\"relu\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# # criar a 3ª camada\n",
    "modelo.add(Conv2D(375, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# # criar a 4ª camada\n",
    "# modelo.add(Conv2D(625, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "# modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# mais uma camada\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(1024, activation=\"relu\"))\n",
    "# camada de saída\n",
    "modelo.add(Dense(49, activation=\"softmax\"))\n",
    "# compilar todas as camadas\n",
    "modelo.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a675ebdf-75ef-43d4-87ac-42ff209448f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "207/207 [==============================] - 46s 219ms/step - loss: 1.9453 - accuracy: 0.4770 - val_loss: 0.3781 - val_accuracy: 0.8814\n",
      "Epoch 2/30\n",
      "207/207 [==============================] - 47s 228ms/step - loss: 0.2180 - accuracy: 0.9317 - val_loss: 0.2136 - val_accuracy: 0.9284\n",
      "Epoch 3/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.1037 - accuracy: 0.9671 - val_loss: 0.1561 - val_accuracy: 0.9519\n",
      "Epoch 4/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.1045 - val_accuracy: 0.9709\n",
      "Epoch 5/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0467 - accuracy: 0.9856 - val_loss: 0.1159 - val_accuracy: 0.9679\n",
      "Epoch 6/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.1055 - val_accuracy: 0.9724\n",
      "Epoch 7/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.2370 - val_accuracy: 0.9423\n",
      "Epoch 8/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.1134 - val_accuracy: 0.9721\n",
      "Epoch 9/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.1152 - val_accuracy: 0.9733\n",
      "Epoch 10/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.1046 - val_accuracy: 0.9741\n",
      "Epoch 11/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.1064 - val_accuracy: 0.9759\n",
      "Epoch 12/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.1512 - val_accuracy: 0.9614\n",
      "Epoch 13/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.1458 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.1419 - val_accuracy: 0.9697\n",
      "Epoch 15/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.1585 - val_accuracy: 0.9646\n",
      "Epoch 16/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.1788 - val_accuracy: 0.9640\n",
      "Epoch 17/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.1739 - val_accuracy: 0.9560\n",
      "Epoch 18/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.3158 - val_accuracy: 0.9314\n",
      "Epoch 19/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.1245 - val_accuracy: 0.9774\n",
      "Epoch 20/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1087 - val_accuracy: 0.9795\n",
      "Epoch 21/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1496 - val_accuracy: 0.9774\n",
      "Epoch 22/30\n",
      "207/207 [==============================] - 47s 229ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.1403 - val_accuracy: 0.9747\n",
      "Epoch 23/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.1240 - val_accuracy: 0.9774\n",
      "Epoch 24/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.1762 - val_accuracy: 0.9640\n",
      "Epoch 25/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 0.1811 - val_accuracy: 0.9658\n",
      "Epoch 26/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.1503 - val_accuracy: 0.9640\n",
      "Epoch 27/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.1251 - val_accuracy: 0.9765\n",
      "Epoch 28/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.1782 - val_accuracy: 0.9747\n",
      "Epoch 29/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.2214 - val_accuracy: 0.9569\n",
      "Epoch 30/30\n",
      "207/207 [==============================] - 48s 230ms/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 0.1511 - val_accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39fc7de250>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# treinar a inteligência artificial\n",
    "modelo.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=49, epochs=30, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77a61eb8-a940-48b6-9696-f2d8b349ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar o modelo em um arquivo\n",
    "modelo.save(\"modelo_treinado.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "646f0afb-387e-4fd1-95cd-ded1dc5b1f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@54455.759] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('resolver/imagem8600letra1.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('resolver/imagem.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "955d4499-4e39-42d6-a7cc-5d6b20f04394",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e99b4ad2-9cc3-4daa-8282-385df7e09070",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=resize_to_fit(img,30,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "adfafa62-02a4-4f5d-89cf-1e89827b4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "edb27930-f4d6-4eca-97f5-77f7826fe06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b32b729-7c1d-4f30-8a03-713c902454ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "letra = modelo.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09907b8b-d40a-428a-a2d5-a90163ae7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "letra= lb.inverse_transform(letra)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d866df0c-3f7e-4320-b60d-719e6afc3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n"
     ]
    }
   ],
   "source": [
    "print(letra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a051d84-fb95-460c-a59b-a7d6b160f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = paths.list_images('letras')\n",
    "\n",
    "for arquivo in imagens:\n",
    "    img = cv2.imread(arquivo)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img=resize_to_fit(img,30,30)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    letra = modelo.predict(img)\n",
    "    letra= lb.inverse_transform(letra)[0]\n",
    "    os.system(f'mv {arquivo} /home/christhian.souza/projects/captcha/base_letras/{letra}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7300579-6e11-4c65-be3a-ccf26e43d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": ".venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

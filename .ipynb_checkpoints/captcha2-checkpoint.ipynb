{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658840c0-8902-42ec-88dc-6b74c0b8964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79575b94-aa1b-4302-b1b0-a7334aaf95b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba12172-18a0-4d57-a61f-7b5c1f79d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratarImagemAdaptativo(origem,destino='ajeitado'):\n",
    "    arquivos = glob.glob(f'{origem}/*')\n",
    "    for arquivo in arquivos:\n",
    "        imagem = cv2.imread(arquivo,0)\n",
    "        imagem = cv2.GaussianBlur(imagem,(5,7),5)\n",
    "        #transformar em escala de cinza\n",
    "        # imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
    "        # _, imagem_tratada = cv2.threshold(imagem_cinza,99,255, cv2.THRESH_TRUNC or cv2.THRESH_OTSU)\n",
    "        imagem_tratada = cv2.adaptiveThreshold(imagem,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,661,138)\n",
    "        nome_arquivo = os.path.basename(arquivo)\n",
    "        cv2.imwrite(f'{destino}/{nome_arquivo}',imagem_tratada)\n",
    "    # arquivos = glob.glob(f\"{destino}/*\")\n",
    "    # for arquivo in arquivos:\n",
    "    #     imagem = Image.open(arquivo)\n",
    "    #     imagem = imagem.convert(\"P\")\n",
    "    #     imagem2 = Image.new(\"P\",imagem.size,255)\n",
    "    #     for x in range(imagem.size[1]):\n",
    "    #         for y in range(imagem.size[0]):\n",
    "    #             cor_pixel = imagem.getpixel((y,x))\n",
    "    #             if cor_pixel < 127:\n",
    "    #                 imagem2.putpixel((y,x),0)\n",
    "    #     nome_arquivo = os.path.basename(arquivo)\n",
    "    #     imagem2.save(f'{destino}/{nome_arquivo}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e92928-3c66-4646-a9fc-65a81447cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tratarImagemAdaptativo('amostra','ajeitado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f60239-fc25-46cb-a591-bed0b2ed43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLetrasAdaptativo(imagem,destino='letras'):\n",
    "    img = cv2.imread(imagem)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    width_cutoff = width // 6\n",
    "    left1 = img[:, :width_cutoff]\n",
    "    right1 = img[:, width_cutoff:]\n",
    "    letras = []\n",
    "    letras.append(img[:, :width_cutoff+20])\n",
    "    letras.append(img[:, width_cutoff+20:2*width_cutoff+12])\n",
    "    letras.append(img[:, 2*width_cutoff+12:3*width_cutoff+12])\n",
    "    letras.append(img[:, 3*width_cutoff+12:4*width_cutoff+12])\n",
    "    letras.append(img[:, 4*width_cutoff+12:5*width_cutoff+12])\n",
    "    letras.append(img[:, 5*width_cutoff+12:])\n",
    "    i=0\n",
    "    for letra in letras:\n",
    "        i+=1\n",
    "        nome_arquivo = os.path.basename(imagem).replace(\".png\",f\"letra{i}.png\")\n",
    "        cv2.imwrite(f'{destino}/{nome_arquivo}',letra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3dddc1-fe7a-488d-95db-a3801633296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = glob.glob('ajeitado/*')\n",
    "for arquivo in arquivos:\n",
    "    getLetrasAdaptativo(arquivo,'letras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162338fa-3c7b-4913-b3f0-2e03649c7626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 21:49:40.461358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-28 21:49:40.461376: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tratar_captcha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtratar_captcha\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tratar_imagens\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquebrar_captcha\u001b[39m():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# importar o modelo que a gente treinou e importar o tradutor\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotulos_modelo.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m arquivo_tradutor:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tratar_captcha'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from helpers import resize_to_fit\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def quebrar_captcha():\n",
    "    # importar o modelo que a gente treinou e importar o tradutor\n",
    "    with open(\"rotulos_modelo.dat\", \"rb\") as arquivo_tradutor:\n",
    "        lb = pickle.load(arquivo_tradutor)\n",
    "\n",
    "    modelo = load_model(\"modelo_treinado.hdf5\")\n",
    "\n",
    "    # usar o modelo pra resolver os catpchas\n",
    "    tratar_imagens(\"resolver\", pasta_destino=\"resolver\")\n",
    "    # ler todos os arquivos da pasta \"resolver\"\n",
    "    ######\n",
    "    arquivos = list(paths.list_images(\"resolver\"))\n",
    "    for arquivo in arquivos:\n",
    "        imagem = cv2.imread(arquivo)\n",
    "        imagem = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
    "        # em preto e branco\n",
    "        _, nova_imagem = cv2.threshold(imagem, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # encontrar os contornos de cada letra\n",
    "        contornos, _ = cv2.findContours(nova_imagem, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        regiao_letras = []\n",
    "\n",
    "        # filtrar os contornos que são realmente de letras\n",
    "        for contorno in contornos:\n",
    "            (x, y, largura, altura) = cv2.boundingRect(contorno)\n",
    "            area = cv2.contourArea(contorno)\n",
    "            if area > 115:\n",
    "                regiao_letras.append((x, y, largura, altura))\n",
    "\n",
    "        regiao_letras = sorted(regiao_letras, key=lambda x: x[0])\n",
    "        # desenhar os contornos e separar as letras em arquivos individuais\n",
    "        imagem_final = cv2.merge([imagem] * 3)\n",
    "        previsao = []\n",
    "\n",
    "        for retangulo in regiao_letras:\n",
    "            x, y, largura, altura = retangulo\n",
    "            imagem_letra = imagem[y - 2:y + altura + 2, x - 2:x + largura + 2]\n",
    "\n",
    "            # dar a letra pra inteligencia artificial descobrir que letra é essa\n",
    "            imagem_letra = resize_to_fit(imagem_letra, 20, 20)\n",
    "\n",
    "            # tratamento para o Keras funcionar\n",
    "            imagem_letra = np.expand_dims(imagem_letra, axis=2)\n",
    "            imagem_letra = np.expand_dims(imagem_letra, axis=0)\n",
    "\n",
    "            letra_prevista = modelo.predict(imagem_letra)\n",
    "            letra_prevista = lb.inverse_transform(letra_prevista)[0]\n",
    "            previsao.append(letra_prevista)\n",
    "\n",
    "        texto_previsao = \"\".join(previsao)\n",
    "        print(texto_previsao)\n",
    "        return texto_previsao\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060514d-3562-4dec-a1a8-4650965cddc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": ".venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
